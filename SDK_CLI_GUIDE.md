# Kepler Framework - GuÃ­a Completa SDK y CLI

> **VersiÃ³n del Framework:** 0.1.0  
> **Ãšltima actualizaciÃ³n:** Diciembre 2024  
> **Estado:** Funcionalidades Core Validadas

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n y FilosofÃ­a](#introducciÃ³n-y-filosofÃ­a)
2. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
3. [CLI - LÃ­nea de Comandos](#cli---lÃ­nea-de-comandos)
4. [SDK - Python API](#sdk---python-api)
5. [Casos de Uso Completos](#casos-de-uso-completos)
6. [EvoluciÃ³n y Roadmap](#evoluciÃ³n-y-roadmap)

---

## ğŸ¯ IntroducciÃ³n y FilosofÃ­a

Kepler Framework ofrece **dos formas de interactuar** con la misma funcionalidad:

### **ğŸ–¥ï¸ CLI (Command Line Interface)**
- Para **operaciones rÃ¡pidas y scripts**
- Ideal para **DevOps y automatizaciÃ³n**
- **ValidaciÃ³n de entorno** y diagnÃ³sticos

### **ğŸ SDK (Software Development Kit)**
- Para **anÃ¡lisis interactivo en Jupyter**
- Ideal para **cientÃ­ficos de datos**
- **IntegraciÃ³n en notebooks** y scripts Python

> **Principio Clave:** Una sola lÃ³gica, dos interfaces. Todo lo que hace el CLI tambiÃ©n lo puede hacer el SDK.

---

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n COMPLETA

### Paso 1: InstalaciÃ³n del Framework

```bash
# Crear entorno virtual (RECOMENDADO)
python -m venv kepler-env
source kepler-env/bin/activate  # Linux/macOS
# kepler-env\Scripts\activate   # Windows

# Instalar desde GitHub (mÃ©todo actual)
git clone https://github.com/lufermalgo/kepler.git /tmp/kepler-install
cd /tmp/kepler-install
pip install .
cd ~ && rm -rf /tmp/kepler-install

# Verificar instalaciÃ³n
kepler --version  # âœ… Debe mostrar: 0.1.0
```

### Paso 2: ConfiguraciÃ³n Inicial

```bash
# Crear estructura de configuraciÃ³n
kepler config init

# Esto crea: ~/.kepler/config.yml
```

### Paso 3: Configurar Credenciales

Editar el archivo `~/.kepler/config.yml`:

```yaml
# ~/.kepler/config.yml
splunk:
  host: "http://localhost:8089"  # Tu servidor Splunk
  hec_host: "http://localhost:8088"  # HTTP Event Collector
  token: "tu-token-rest-api"     # Token para REST API
  hec_token: "tu-token-hec"      # Token para HEC
  verify_ssl: false              # Para desarrollo local

gcp:
  project_id: "tu-proyecto-gcp"
  region: "us-central1"
  credentials_path: "~/.gcp/service-account.json"
```

### Paso 4: Validar ConfiguraciÃ³n

```bash
# ValidaciÃ³n completa en 5 pasos
kepler validate

# Salida esperada:
# âœ… Step 1/5: Prerequisites validation
# âœ… Step 2/5: GCP configuration  
# âœ… Step 3/5: Project configuration
# âœ… Step 4/5: Splunk connectivity
# âœ… Step 5/5: Splunk indexes validation
```

---

## ğŸ–¥ï¸ CLI - LÃ­nea de Comandos

### **Comandos Principales (Validados y Funcionando)**

#### **1. `kepler validate` - DiagnÃ³stico Completo**

```bash
# ValidaciÃ³n completa del entorno
kepler validate

# ValidaciÃ³n especÃ­fica de Splunk
kepler validate --splunk-only

# ValidaciÃ³n con output detallado
kepler validate --verbose
```

**QuÃ© valida:**
- âœ… Python 3.8+ instalado
- âœ… Dependencias del framework
- âœ… ConfiguraciÃ³n GCP
- âœ… Conectividad Splunk (REST API + HEC)
- âœ… Existencia de Ã­ndices `kepler_lab` y `kepler_metrics`
- âœ… Auto-creaciÃ³n de Ã­ndices si no existen

#### **2. `kepler extract` - ExtracciÃ³n de Datos**

```bash
# ExtracciÃ³n bÃ¡sica con SPL personalizado
kepler extract "search index=kepler_lab" --output data.csv

# ExtracciÃ³n con rango de tiempo
kepler extract "search index=kepler_lab sensor_type=temperature" \
    --earliest "-7d" --latest "now" --output temperature_data.csv

# ExtracciÃ³n de mÃ©tricas
kepler extract "| mstats avg(_value) WHERE index=kepler_metrics metric_name=* earliest=-30d span=1h by metric_name" \
    --output metrics_hourly.csv

# ExtracciÃ³n con lÃ­mite de registros
kepler extract "search index=kepler_lab" --limit 1000 --output sample_data.csv
```

**ParÃ¡metros disponibles:**
- `--output`: Archivo de salida (CSV)
- `--earliest`: Tiempo inicial (ej: `-7d`, `-24h`, `-1h`)
- `--latest`: Tiempo final (por defecto: `now`)
- `--limit`: MÃ¡ximo nÃºmero de registros
- `--format`: Formato de salida (`csv`, `json`) - por defecto: `csv`

#### **3. `kepler config` - GestiÃ³n de ConfiguraciÃ³n**

```bash
# Inicializar configuraciÃ³n
kepler config init

# Mostrar configuraciÃ³n actual (sin credenciales)
kepler config show

# Validar configuraciÃ³n
kepler config validate

# Mostrar ubicaciones de archivos
kepler config paths
```

### **Comandos en Desarrollo (PrÃ³ximos Sprints)**

```bash
# ğŸš§ EN DESARROLLO - Sprint actual
kepler train data.csv --target temperature --algorithm random_forest
kepler train data.csv --target anomaly --algorithm xgboost --test-size 0.3

# ğŸš§ PLANEADO - Sprint 9-10  
kepler deploy model.pkl --name my-model --env production
kepler predict https://endpoint.run.app/predict '{"temperature": 25.5}'

# ğŸš§ PLANEADO - Sprint 11-12
kepler monitor --model my-model --dashboard splunk
kepler logs --model my-model --tail
```

---

## ğŸ SDK - Python API

### **Import y ConfiguraciÃ³n**

```python
# Import sÃºper simple - sin configuraciÃ³n manual
import kepler as kp

# El SDK usa automÃ¡ticamente la configuraciÃ³n de ~/.kepler/config.yml
print(f"Kepler Framework version: {kp.__version__}")
```

### **ExtracciÃ³n de Datos con `kp.data.from_splunk()`**

#### **ExtracciÃ³n BÃ¡sica de Eventos**

```python
# Eventos de sensores - Ãºltimos 7 dÃ­as
eventos = kp.data.from_splunk(
    spl="search index=kepler_lab sensor_type=temperature",
    earliest="-7d",
    latest="now"
)

print(f"Eventos extraÃ­dos: {len(eventos)}")
print(f"Columnas: {list(eventos.columns)}")
print(eventos.head())
```

**Resultado validado:**
```
Eventos extraÃ­dos: 867
Columnas: ['_time', 'sensor_id', 'sensor_type', 'area', 'value', 'unit']
```

#### **ExtracciÃ³n de MÃ©tricas**

```python
# MÃ©tricas - Ãºltimos 30 dÃ­as  
metricas = kp.data.from_splunk(
    spl="| mstats latest(_value) as ultimo_valor WHERE index=kepler_metrics metric_name=* earliest=-30d by metric_name"
)

print(f"Tipos de mÃ©tricas: {len(metricas)}")
print("MÃ©tricas disponibles:")
for metrica in metricas['metric_name'].tolist():
    print(f"  - {metrica}")
```

**Resultado validado:**
```
Tipos de mÃ©tricas: 16
MÃ©tricas disponibles:
  - flow_rate.SENSOR_003
  - power_consumption.SENSOR_002
  - vibration.SENSOR_007
  - temperature.SENSOR_001
  [... y 12 mÃ¡s]
```

#### **Control de Tiempo Avanzado**

```python
import pandas as pd

# Comparar diferentes rangos temporales
rangos = ["-1h", "-24h", "-7d", "-30d"]
resultados = {}

for rango in rangos:
    datos = kp.data.from_splunk(
        spl="search index=kepler_lab",
        earliest=rango,
        latest="now"
    )
    resultados[rango] = len(datos)
    
print("Datos por rango temporal:")
for rango, cantidad in resultados.items():
    print(f"  {rango}: {cantidad} registros")
```

**Resultado validado:**
```
Datos por rango temporal:
  -1h: 0 registros
  -24h: 90 registros  
  -7d: 2890 registros
  -30d: 2890 registros
```

### **SPL Personalizado Avanzado**

#### **AnÃ¡lisis de Series Temporales**

```python
# Series temporales de mÃ©tricas por hora
series_temporales = kp.data.from_splunk(
    spl="""
    | mstats avg(_value) as promedio 
    WHERE index=kepler_metrics metric_name=* earliest=-7d 
    span=1h by metric_name
    """
)

# Procesar para anÃ¡lisis
series_temporales['timestamp'] = pd.to_datetime(series_temporales['_time'])
series_temporales['promedio'] = pd.to_numeric(series_temporales['promedio'])

# EstadÃ­sticas por mÃ©trica
stats = series_temporales.groupby('metric_name')['promedio'].agg([
    'mean', 'std', 'min', 'max', 'count'
])

print("EstadÃ­sticas por mÃ©trica:")
print(stats.head())
```

#### **AnÃ¡lisis de Eventos Complejos**

```python
# AnÃ¡lisis multi-sensor con filtros
analisis_sensores = kp.data.from_splunk(
    spl="""
    search index=kepler_lab 
    | eval hour=strftime(_time, "%H")
    | stats avg(value) as promedio, count as eventos by sensor_type, area, hour
    | where eventos > 5
    """,
    earliest="-7d"
)

print("AnÃ¡lisis por sensor, Ã¡rea y hora:")
print(analisis_sensores.head(10))
```

### **Manejo de Errores Inteligente**

```python
# El SDK captura y muestra errores de Splunk claramente
try:
    datos = kp.data.from_splunk(
        spl="| mstats avg(_value) WHERE index=kepler_metrics"  # Query incompleta
    )
except Exception as e:
    print(f"Error capturado: {e}")
    # El framework muestra error especÃ­fico de Splunk + sugerencia
```

**Salida del manejo de errores:**
```
âŒ Splunk Error: You must include at least one metric_name filter
ğŸ” Query: | mstats avg(_value) WHERE index=kepler_metrics
ğŸ’¡ Tip: Check the SPL syntax according to Splunk documentation
```

---

## ğŸ“Š Casos de Uso Completos

### **Caso 1: AnÃ¡lisis Exploratorio de Datos (CientÃ­fico de Datos)**

```python
import kepler as kp
import pandas as pd
import matplotlib.pyplot as plt

# 1. Explorar quÃ© datos hay disponibles
print("=== EXPLORACIÃ“N INICIAL ===")

# Ver mÃ©tricas disponibles  
metricas_disponibles = kp.data.from_splunk(
    spl="| mcatalog values(metric_name) WHERE index=kepler_metrics"
)
print(f"MÃ©tricas disponibles: {len(metricas_disponibles)}")

# Ver eventos recientes
eventos_recientes = kp.data.from_splunk(
    spl="search index=kepler_lab | head 100"
)
print(f"Tipos de sensores: {eventos_recientes['sensor_type'].unique()}")

# 2. AnÃ¡lisis temporal
print("\n=== ANÃLISIS TEMPORAL ===")

# Comparar volÃºmenes por perÃ­odo
periodos = {
    "Ãšltima hora": "-1h",
    "Ãšltimas 24h": "-24h", 
    "Ãšltimos 7 dÃ­as": "-7d"
}

for nombre, rango in periodos.items():
    datos = kp.data.from_splunk(
        spl="search index=kepler_lab",
        earliest=rango
    )
    print(f"{nombre}: {len(datos)} registros")

# 3. AnÃ¡lisis por tipo de sensor
print("\n=== ANÃLISIS POR SENSOR ===")

temperatura_data = kp.data.from_splunk(
    spl="search index=kepler_lab sensor_type=temperature",
    earliest="-7d"
)

print(f"Datos de temperatura: {len(temperatura_data)} registros")
print(f"Rango temporal: {temperatura_data['_time'].min()} a {temperatura_data['_time'].max()}")
print(f"EstadÃ­sticas bÃ¡sicas:")
print(temperatura_data['value'].describe())
```

### **Caso 2: Pipeline de Datos Automatizado (DevOps/Engineer)**

```bash
#!/bin/bash
# extract_daily_data.sh - Pipeline automatizado

echo "=== PIPELINE DIARIO DE EXTRACCIÃ“N ==="

# 1. Validar entorno
echo "Validando configuraciÃ³n..."
kepler validate || exit 1

# 2. Extraer datos del dÃ­a anterior
echo "Extrayendo eventos del dÃ­a anterior..."
kepler extract "search index=kepler_lab earliest=-1d@d latest=@d" \
    --output "data/events_$(date +%Y%m%d).csv"

# 3. Extraer mÃ©tricas horarias
echo "Extrayendo mÃ©tricas horarias..."
kepler extract "| mstats avg(_value) WHERE index=kepler_metrics metric_name=* earliest=-1d@d latest=@d span=1h by metric_name" \
    --output "data/metrics_hourly_$(date +%Y%m%d).csv"

# 4. Generar reporte bÃ¡sico
echo "Generando reporte..."
python generate_daily_report.py "data/events_$(date +%Y%m%d).csv"

echo "Pipeline completado exitosamente"
```

### **Caso 3: Monitoreo en Tiempo Real (Jupyter Notebook)**

```python
# Notebook: real_time_monitoring.ipynb

import kepler as kp
import time
from datetime import datetime

print("=== MONITOR EN TIEMPO REAL ===")

def monitor_loop():
    """Monitor continuo de mÃ©tricas crÃ­ticas"""
    
    while True:
        print(f"\n[{datetime.now().strftime('%H:%M:%S')}] Checking metrics...")
        
        # Obtener mÃ©tricas de los Ãºltimos 15 minutos
        metricas_recientes = kp.data.from_splunk(
            spl="| mstats latest(_value) as valor WHERE index=kepler_metrics metric_name=power_consumption.* earliest=-15m by metric_name"
        )
        
        if len(metricas_recientes) > 0:
            # Detectar anomalÃ­as simples
            for _, row in metricas_recientes.iterrows():
                metrica = row['metric_name']
                valor = float(row['valor'])
                
                # Umbral simple de ejemplo
                if valor > 1000:  # Consumo alto
                    print(f"âš ï¸  ALERTA: {metrica} = {valor:.2f} (Alto consumo)")
                elif valor < 100:  # Consumo muy bajo  
                    print(f"ğŸ” INFO: {metrica} = {valor:.2f} (Consumo bajo)")
                else:
                    print(f"âœ… OK: {metrica} = {valor:.2f}")
        else:
            print("âŒ No se encontraron mÃ©tricas recientes")
            
        # Esperar 60 segundos antes del prÃ³ximo check
        time.sleep(60)

# Ejecutar monitor (detener con Ctrl+C)
try:
    monitor_loop()
except KeyboardInterrupt:
    print("\nMonitor detenido por el usuario")
```

---

## ğŸ”„ EvoluciÃ³n y Roadmap

### **âœ… SPRINT 1-8: FUNDACIÃ“N (COMPLETADO)**

#### **CLI Implementado:**
- âœ… `kepler validate` - ValidaciÃ³n completa en 5 pasos
- âœ… `kepler extract` - ExtracciÃ³n con SPL personalizado
- âœ… `kepler config` - GestiÃ³n de configuraciÃ³n

#### **SDK Implementado:**
- âœ… `import kepler as kp` - Import directo
- âœ… `kp.data.from_splunk()` - ExtracciÃ³n flexible
- âœ… ParÃ¡metros `earliest`/`latest` para control temporal
- âœ… Manejo inteligente de errores de Splunk

#### **Capacidades Validadas:**
- âœ… **2,890 eventos** extraÃ­dos exitosamente
- âœ… **16 tipos de mÃ©tricas** funcionando
- âœ… **Control temporal:** 32x diferencia entre 24h vs 7d
- âœ… **Notebooks Jupyter** integraciÃ³n completa

### **ğŸš§ SPRINT 9-10: ENTRENAMIENTO ML (EN DESARROLLO)**

#### **CLI Nuevo:**
```bash
# Comandos de ML que se van a implementar
kepler train data.csv --target temperature --algorithm random_forest
kepler train data.csv --target anomaly --algorithm xgboost --params config.json
kepler model list  # Listar modelos entrenados
kepler model info model_20241215_rf.pkl  # Info del modelo
```

#### **SDK Nuevo:**
```python
# API de ML que se va a implementar
model = kp.train.sklearn(
    data=eventos,
    target='temperature', 
    algorithm='RandomForest',
    test_size=0.3
)

# Predicciones locales
predictions = model.predict(test_data)
print(f"Accuracy: {model.metrics['accuracy']}")
```

### **ğŸš§ SPRINT 11-12: DEPLOYMENT GCP (PLANEADO)**

#### **CLI Deployment:**
```bash
# Deploy a Cloud Run
kepler deploy model.pkl --name temp-predictor --env production

# GestiÃ³n de deployments  
kepler deploy list
kepler deploy logs temp-predictor --tail
kepler deploy scale temp-predictor --instances 3
```

#### **SDK Deployment:**
```python
# Deploy programÃ¡tico
endpoint = kp.deploy.cloud_run(
    model=trained_model,
    name="anomaly-detector",
    environment="production"
)

# Predicciones remotas
result = endpoint.predict({"sensor_data": [25.5, 2.1, 0.8]})
```

### **ğŸš§ SPRINT 13-16: PRODUCCIÃ“N COMPLETA (FUTURO)**

#### **Funcionalidades Avanzadas:**
- ğŸ”„ **Escritura automÃ¡tica** de predicciones a Splunk
- ğŸ“Š **Dashboards automÃ¡ticos** en Splunk para monitoreo
- ğŸ”§ **Pipeline completos** de CI/CD
- ğŸ“¦ **DistribuciÃ³n PyPI** (`pip install kepler-framework`)

---

## ğŸ“š Recursos Adicionales

### **Notebooks de Ejemplo (Validados):**
- `test-lab/notebooks/metrics_analysis_clean.ipynb` - AnÃ¡lisis de mÃ©tricas paso a paso
- `test-lab/notebooks/events_analysis.ipynb` - AnÃ¡lisis de eventos completo

### **Archivos de ConfiguraciÃ³n:**
- `~/.kepler/config.yml` - ConfiguraciÃ³n global segura
- `proyecto/kepler.yml` - ConfiguraciÃ³n especÃ­fica del proyecto

### **DocumentaciÃ³n TÃ©cnica:**
- `README.md` - GuÃ­a de inicio rÃ¡pido
- `VALIDATION_STATUS.md` - Estado tÃ©cnico detallado
- Este archivo: `SDK_CLI_GUIDE.md` - GuÃ­a completa de uso

---

> **ğŸ’¡ Tip Final:** Comienza siempre con `kepler validate` para asegurar que todo estÃ© configurado correctamente. Luego usa `kepler extract` para explorar tus datos antes de entrenar modelos.

> **ğŸ¯ Estado Actual:** Las funciones de extracciÃ³n y anÃ¡lisis estÃ¡n completamente validadas y listas para uso en producciÃ³n. Las funciones de ML estÃ¡n en desarrollo activo.